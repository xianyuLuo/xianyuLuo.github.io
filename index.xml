<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>xianyuLuo Blog</title>
    <link>http://xianyuluo.com/</link>
    <description>Recent content on xianyuLuo Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>cn-ZH</language>
    <lastBuildDate>Tue, 26 Mar 2019 09:42:15 +0800</lastBuildDate>
    
	<atom:link href="http://xianyuluo.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Prometheus监控k8s(三)——业务指标采集</title>
      <link>http://xianyuluo.com/post/prometheus%E7%9B%91%E6%8E%A7k8s%E4%B8%89%E4%B8%9A%E5%8A%A1%E6%8C%87%E6%A0%87%E9%87%87%E9%9B%86/</link>
      <pubDate>Tue, 26 Mar 2019 09:42:15 +0800</pubDate>
      
      <guid>http://xianyuluo.com/post/prometheus%E7%9B%91%E6%8E%A7k8s%E4%B8%89%E4%B8%9A%E5%8A%A1%E6%8C%87%E6%A0%87%E9%87%87%E9%9B%86/</guid>
      <description>背景 由于容器化和微服务的大力发展，Kubernetes基本已经统一了容器管理方案，当我们使用Kubernetes来进行容器化管理的时候，全面监控Kubernetes也就成了我们第一个需要探索的问题。我们需要监控kubernetes的ingress、service、deployment、pod&amp;hellip;&amp;hellip;等等服务，以达到随时掌握Kubernetes集群的内部状况。
此文章也是Prometheus监控系列的第三篇，具体描述了在Kubernetes中使用Prometheus来采集业务指标。多数为思想指导，会列出两个例子。第一个例子是针对部署在Kubernetes中的服务，另外一个例子是非Kubernetes部署的服务。前者为使用“动态采集”，后者使用“静态采集”。
概念 要使用Prometheus实现自动采集业务指标数据真的非常简单，只需要2步
1、业务侧实现一个接口，返回Prometheus规范化数据，如下：
traefik_entrypoint_requests_total{code=&amp;quot;302&amp;quot;,entrypoint=&amp;quot;https&amp;quot;,method=&amp;quot;HEAD&amp;quot;,protocol=&amp;quot;http&amp;quot;} 1 traefik_entrypoint_requests_total{code=&amp;quot;302&amp;quot;,entrypoint=&amp;quot;https&amp;quot;,method=&amp;quot;POST&amp;quot;,protocol=&amp;quot;http&amp;quot;} 1 traefik_entrypoint_requests_total{code=&amp;quot;304&amp;quot;,entrypoint=&amp;quot;http&amp;quot;,method=&amp;quot;GET&amp;quot;,protocol=&amp;quot;http&amp;quot;} 15 traefik_entrypoint_requests_total{code=&amp;quot;304&amp;quot;,entrypoint=&amp;quot;https&amp;quot;,method=&amp;quot;GET&amp;quot;,protocol=&amp;quot;http&amp;quot;} 5951 traefik_entrypoint_requests_total{code=&amp;quot;400&amp;quot;,entrypoint=&amp;quot;https&amp;quot;,method=&amp;quot;GET&amp;quot;,protocol=&amp;quot;http&amp;quot;} 149 traefik_entrypoint_requests_total{code=&amp;quot;403&amp;quot;,entrypoint=&amp;quot;http&amp;quot;,method=&amp;quot;GET&amp;quot;,protocol=&amp;quot;http&amp;quot;} 2 traefik_entrypoint_requests_total{code=&amp;quot;403&amp;quot;,entrypoint=&amp;quot;https&amp;quot;,method=&amp;quot;HEAD&amp;quot;,protocol=&amp;quot;http&amp;quot;} 2 traefik_entrypoint_requests_total{code=&amp;quot;404&amp;quot;,entrypoint=&amp;quot;http&amp;quot;,method=&amp;quot;GET&amp;quot;,protocol=&amp;quot;http&amp;quot;} 680 traefik_entrypoint_requests_total{code=&amp;quot;404&amp;quot;,entrypoint=&amp;quot;http&amp;quot;,method=&amp;quot;HEAD&amp;quot;,protocol=&amp;quot;http&amp;quot;} 15 traefik_entrypoint_requests_total{code=&amp;quot;404&amp;quot;,entrypoint=&amp;quot;http&amp;quot;,method=&amp;quot;POST&amp;quot;,protocol=&amp;quot;http&amp;quot;} 674   每行代表一个监控项，以KEY VALUE形式返回，KEY可以带上0个或多个属性，多个属性以 “，”分隔。在Prometheus中查询数据的时候，可以用这些属性作为筛选条件。 Key中不能包含 “-” 等特殊字符，最好使用 “_” 。  2、运维侧部署的时候，在svc上带上3个标签</description>
    </item>
    
    <item>
      <title>Prometheus监控k8s(二)——监控部署</title>
      <link>http://xianyuluo.com/post/prometheus%E7%9B%91%E6%8E%A7k8s%E4%BA%8C%E7%9B%91%E6%8E%A7%E9%83%A8%E7%BD%B2/</link>
      <pubDate>Mon, 18 Mar 2019 15:51:18 +0800</pubDate>
      
      <guid>http://xianyuluo.com/post/prometheus%E7%9B%91%E6%8E%A7k8s%E4%BA%8C%E7%9B%91%E6%8E%A7%E9%83%A8%E7%BD%B2/</guid>
      <description>背景 由于容器化和微服务的大力发展，Kubernetes基本已经统一了容器管理方案，当我们使用Kubernetes来进行容器化管理的时候，全面监控Kubernetes也就成了我们第一个需要探索的问题。我们需要监控kubernetes的ingress、service、deployment、pod&amp;hellip;&amp;hellip;等等服务，已达到随时掌握Kubernetes集群的内部状况。
此文章是Prometheus监控系列的第二篇，基于上一篇讲解了怎么对Kubernetes集群实施Prometheus监控。
Prometheus部署 在k8s上部署Prometheus十分简单，下面给的例子中将Prometheus部署到prometheus命名空间。
部署——监控数据采集 Prometheus 将kube-state-metrics和prometheus分开部署，先部署prometheus。
prometheus-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRole metadata: name: prometheus rules: - apiGroups: [&amp;quot;&amp;quot;] resources: - nodes - nodes/proxy - services - endpoints - pods verbs: [&amp;quot;get&amp;quot;, &amp;quot;list&amp;quot;, &amp;quot;watch&amp;quot;] - apiGroups: - extensions resources: - ingresses verbs: [&amp;quot;get&amp;quot;, &amp;quot;list&amp;quot;, &amp;quot;watch&amp;quot;] - nonResourceURLs: [&amp;quot;/metrics&amp;quot;] verbs: [&amp;quot;get&amp;quot;] --- apiVersion: v1 kind: ServiceAccount metadata: name: prometheus namespace: prometheus --- apiVersion: rbac.</description>
    </item>
    
    <item>
      <title>Prometheus监控k8s(一)——监控框架调研</title>
      <link>http://xianyuluo.com/post/prometheus%E7%9B%91%E6%8E%A7k8s%E4%B8%80%E7%9B%91%E6%8E%A7%E6%A1%86%E6%9E%B6%E8%B0%83%E7%A0%94/</link>
      <pubDate>Tue, 12 Mar 2019 22:11:13 +0800</pubDate>
      
      <guid>http://xianyuluo.com/post/prometheus%E7%9B%91%E6%8E%A7k8s%E4%B8%80%E7%9B%91%E6%8E%A7%E6%A1%86%E6%9E%B6%E8%B0%83%E7%A0%94/</guid>
      <description>背景 由于容器化和微服务的大力发展，Kubernetes基本已经统一了容器管理方案，当我们使用Kubernetes来进行容器化管理的时候，全面监控Kubernetes也就成了我们第一个需要探索的问题。我们需要监控kubernetes的ingress、service、deployment、pod&amp;hellip;&amp;hellip;等等服务，已达到随时掌握Kubernetes集群的内部状况。
此文章是Prometheus监控系列的第一篇，目的也很明确，旨在于寻找一套能够胜任kubernetes集群监控的架构。
k8s监控方案调研 1、cAdvisor + InfluxDB + Grafana 2、Heapster + InfluxDB + Grafana [x] 3、Promethus + kube-state-metrics + Grafana</description>
    </item>
    
    <item>
      <title>Ablout</title>
      <link>http://xianyuluo.com/ablout/</link>
      <pubDate>Sun, 10 Mar 2019 16:28:54 +0800</pubDate>
      
      <guid>http://xianyuluo.com/ablout/</guid>
      <description> test </description>
    </item>
    
    <item>
      <title>SRE附录C~事故状态文档示范</title>
      <link>http://xianyuluo.com/post/sre%E9%99%84%E5%BD%95c-%E4%BA%8B%E6%95%85%E7%8A%B6%E6%80%81%E6%96%87%E6%A1%A3%E7%A4%BA%E8%8C%83/</link>
      <pubDate>Sun, 10 Mar 2019 12:11:03 +0800</pubDate>
      
      <guid>http://xianyuluo.com/post/sre%E9%99%84%E5%BD%95c-%E4%BA%8B%E6%95%85%E7%8A%B6%E6%80%81%E6%96%87%E6%A1%A3%E7%A4%BA%E8%8C%83/</guid>
      <description>莎士比亚搜索服务 新韵文+过载事故：2015-10-21 （沟通负责人会随时更新事故概要）
摘要 莎士比亚搜索服务由于新发现的韵文不在索引中而处于连锁故障状态
状态 活跃，事故编号 ##45
事故处理中心 IRC #shakespeare 频道
事故处理组织架构：（参与人）  目前事故负责人：xxx 运维负责人： 计划负责人： 沟通负责人：
 下一个事故总负责人：待定 （沟通负责人在交接班时或者每4小时更新一次）</description>
    </item>
    
    <item>
      <title>SRE附录D~事后总结示范</title>
      <link>http://xianyuluo.com/post/sre%E9%99%84%E5%BD%95d-%E4%BA%8B%E5%90%8E%E6%80%BB%E7%BB%93%E7%A4%BA%E8%8C%83/</link>
      <pubDate>Sun, 10 Mar 2019 12:10:18 +0800</pubDate>
      
      <guid>http://xianyuluo.com/post/sre%E9%99%84%E5%BD%95d-%E4%BA%8B%E5%90%8E%E6%80%BB%E7%BB%93%E7%A4%BA%E8%8C%83/</guid>
      <description>莎士比亚新询文事故总结（事故编号 #465） 日期 2015-10-21
作者 Jennifer、martym、agoogler
目前状态 已经终稿，待办事项正在进行中
摘要 莎士比亚搜索服务出现66分钟的故障，由于新发现了一篇韵文，导致用户流量暴涨。
事故影响 预计12.1亿个请求丢失，没有损失任何收入。
根源问题 由于异常的高负债情况以及搜索词语在 Shakespeare Corpus 中不存在时的一项资源泄露导致的连锁故障的发生，新发现的韵文使用了一个之前从未在莎士比亚文献中出现的词语。这恰恰是用户大量搜索的关键词！在日常情况下。这种资源泄露导致的任务崩溃现象，由于出现非常不频繁，而没有被注意到。
触发条件 潜伏性的Bug被大量上涨流量所触发</description>
    </item>
    
    <item>
      <title>SRE附录F~生产环境会议记录示范</title>
      <link>http://xianyuluo.com/post/sre%E9%99%84%E5%BD%95f-%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%BC%9A%E8%AE%AE%E8%AE%B0%E5%BD%95%E7%A4%BA%E8%8C%83/</link>
      <pubDate>Sun, 10 Mar 2019 12:09:02 +0800</pubDate>
      
      <guid>http://xianyuluo.com/post/sre%E9%99%84%E5%BD%95f-%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%BC%9A%E8%AE%AE%E8%AE%B0%E5%BD%95%E7%A4%BA%E8%8C%83/</guid>
      <description>日期 2015-10-23
参与者 agoogler、clarac、docbrown、jennifer和martym
公告  大型事故（#465），造成错误预算耗尽  之前的待办事项评审  确保山羊传送器可以用于传送牛奶  ——质子加速中的非线性特质可以预知了，应该可以在几天内解决准确性问题
事故回顾  新韵文的发现（事故465）  —— 12.1亿个请求在连锁故障与潜伏先bug的共同作用下丢失，索引中不存在新的韵文和未预料的流量</description>
    </item>
    
    <item>
      <title>Ingress介绍</title>
      <link>http://xianyuluo.com/post/ingress%E4%BB%8B%E7%BB%8D/</link>
      <pubDate>Fri, 09 Nov 2018 18:29:30 +0800</pubDate>
      
      <guid>http://xianyuluo.com/post/ingress%E4%BB%8B%E7%BB%8D/</guid>
      <description>&lt;h1 id=&#34;概念&#34;&gt;概念&lt;/h1&gt;

&lt;p&gt;Ingress是kubernetes1.1之后官方提出的一个标准，按照这套标准它有多种实现，比如 nginx-ingress-controller、traefik-ingress-controller、kong-ingress-controller，这3中都是官方推荐的。Ingress的出现解决了Service的短板：只能在tcp层面做负载均衡。而ingress可以方便的做http/https层面的负载均衡。一个是在4层，一个在7层。ingress就是控制客户端从入口连接到k8s集群服务的规则的集合！&lt;/p&gt;

&lt;h3 id=&#34;ingress出现之前-服务暴露是这样的&#34;&gt;ingress出现之前，服务暴露是这样的：&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://dl-blog.laoxianyu.cn/image2018-8-10_14-6-49.png&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;ingress出现之后-服务暴露是这样的&#34;&gt;ingress出现之后，服务暴露是这样的：&lt;/h3&gt;</description>
    </item>
    
    <item>
      <title>使用lets encript申请通配符证书</title>
      <link>http://xianyuluo.com/post/%E4%BD%BF%E7%94%A8let-s-encript%E7%94%B3%E8%AF%B7%E9%80%9A%E9%85%8D%E7%AC%A6%E8%AF%81%E4%B9%A6/</link>
      <pubDate>Wed, 07 Nov 2018 22:42:59 +0800</pubDate>
      
      <guid>http://xianyuluo.com/post/%E4%BD%BF%E7%94%A8let-s-encript%E7%94%B3%E8%AF%B7%E9%80%9A%E9%85%8D%E7%AC%A6%E8%AF%81%E4%B9%A6/</guid>
      <description>什么是 Let’s Encrypt Let’s Encrypt 是国外一个公共的免费 SSL 项目，由 Linux 基金会托管。它的来头不小，由 Mozilla、思科、Akamai、IdenTrust 和 EFF 等组织发起，目的就是向网站自动签发和管理免费证书。以便加速互联网由 HTTP 过渡到 HTTPS，目前 Facebook 等大公司开始加入赞助行列。</description>
    </item>
    
    <item>
      <title>traefik在kubernetes中的应用</title>
      <link>http://xianyuluo.com/post/traefik%E5%9C%A8kubernetes%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/</link>
      <pubDate>Mon, 10 Sep 2018 22:08:46 +0800</pubDate>
      
      <guid>http://xianyuluo.com/post/traefik%E5%9C%A8kubernetes%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/</guid>
      <description>目的： 通过本篇文章，能够简单了解和掌握Traefik在Kubernetes中的应用
如果不了解ingress和ingress-controller概念，请先看前一篇文章。http://km.oa.dragonest.com/x/RoFf
traefik介绍： 开源的微服务网关服务，支持Mesos、Docker、Rancher、Kubernetes等等，也支持直接部署在物理服务器。能够实现负载均衡、HTTPS、自动更新Ingerss配置等等
traefik部署： traefik-deployment部署 apiVersion: extensions/v1beta1 kind: Deployment metadata: name: traefik-ingress-controller namespace: traefik labels: k8s-app: traefik-ingress-lb spec: replicas: 1 selector: matchLabels: k8s-app: traefik-ingress-lb template: metadata: labels: k8s-app: traefik-ingress-lb name: traefik-ingress-lb spec: nodeSelector: traefik-controller-qa: &amp;quot;yes&amp;quot; serviceAccountName: traefik-ingress-controller terminationGracePeriodSeconds: 60 volumes: - name: ssl secret: secretName: traefik-cert - name: config configMap: name: traefik-conf containers: - image: traefik name: traefik-ingress-lb volumeMounts: - mountPath: &amp;quot;/ssl&amp;quot; name: &amp;quot;ssl&amp;quot; - mountPath: &amp;quot;/config&amp;quot; name: &amp;quot;config&amp;quot; ports: - name: http containerPort: 80 - name: admin containerPort: 8080 - name: https containerPort: 443 args: - --configFile=/config/traefik.</description>
    </item>
    
    <item>
      <title>关于自己</title>
      <link>http://xianyuluo.com/about/</link>
      <pubDate>Sat, 12 May 2018 23:48:12 +0800</pubDate>
      
      <guid>http://xianyuluo.com/about/</guid>
      <description>学习经历  2004——2010年 四川省雅安市雨城区严桥镇 严桥三九中心校 2010——2013年 四川省雅安市雨城区 雅安市第二中学 2013——2017年 四川省乐山市市中区 乐山师范学院-计算机科学与技术-师范专业  工作经历  2016年11月——至今 成都龙渊网络科技有限公司 运维工程师  工作内容  各云平台维护；ali / hw / aws / ks / qcloud / ucloud / qingcloud / ws 基础研发部门的环境支持、应用部署、CICD实施和维护；gitlab / gitlab-ci / drone / jenkins / kubernetes / traefik / konga 大数据环境支持和维护；spark / hadoop / es / kibana 运维监控系统完善；zabbix / prometheus / send_msg 游戏业务运维；kubernetes / prometheus / jenkins / gitlab-ci 运维账务管理系统RMS完善；python / mysql / rancher / kubernetes  近况 新业务基本都使用了kubernetes技术，包括公司基础服部署务也在往k8s转。最近在研究k8s监控及k8s高级用法</description>
    </item>
    
    <item>
      <title>归档</title>
      <link>http://xianyuluo.com/archives/</link>
      <pubDate>Mon, 12 Mar 2018 23:48:12 +0800</pubDate>
      
      <guid>http://xianyuluo.com/archives/</guid>
      <description> ttt </description>
    </item>
    
    <item>
      <title>tcp交互数据和块数据处理</title>
      <link>http://xianyuluo.com/post/tcp%E4%BA%A4%E4%BA%92%E6%95%B0%E6%8D%AE%E5%92%8C%E5%9D%97%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/</link>
      <pubDate>Wed, 29 Nov 2017 20:41:05 +0800</pubDate>
      
      <guid>http://xianyuluo.com/post/tcp%E4%BA%A4%E4%BA%92%E6%95%B0%E6%8D%AE%E5%92%8C%E5%9D%97%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/</guid>
      <description>前言 目前建立在TCP协议上的网络协议特别多，有telnet，ssh，有ftp，有http等等。这些协议又可以根据数据吞吐量来大致分成两大类： + (1)交互数据类型 例如telnet，ssh，这种类型的协议在大多数情况下只是做小流量的数据交换，比如说按一下键盘，回显一些文字等等。 + (2)数据成块类型 例如ftp，这种类型的协议要求TCP能尽量的运载数据，把数据的吞吐量做到最大，并尽可能的提高效率。针对这两种情况，TCP给出了两种不同的策略来进行数据传输。
TCP的交互数据流 对于交互性要求比较高的应用，TCP给出两个策略来提高发送效率和减低网络负担： - (1)捎带ACK - (2)Nagle算法（一次尽量多的发数据）
捎带ACK的发送方式 &amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;当主机收到远程主机的TCP数据报之后，通常不马上发送ACK数据报，而是等上一个短暂的时间，如果这段时间里面主机还有发送到远程主机的TCP数据报，那么就把这个ACK数据报“捎带”着发送出去，把本来两个TCP数据报整合成一个发送。一般的，这个时间是200ms。可以明显地看到这个策略可以把TCP数据报的利用率提高很多。
Nagle算法 &amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;Nagle算法是说，当主机A给主机B发送了一个TCP数据报并进入等待主机B的ACK数据报的状态时，TCP的输出缓冲区里面只能有一个TCP数据报，并且，这个数据报不断地收集后来的数据，整合成一个大的数据报，等到B主机的ACK包一到，就把这些数据“一股脑”的发送出去。这样可以较少交互，减轻压力。
TCP的成块数据流 &amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;对于FTP这样对于数据吞吐量有较高要求的要求，将总是希望每次尽量多的发送数据到对方主机，就算是有点延迟也无所谓。TCP也提供了一整套的策略来支持这样的需求。TCP协议中有16个bit表示“窗口”的大小，这是策略的核心。 传输数据时ACK的问题 &amp;ensp;&amp;ensp;&amp;ensp;&amp;ensp;在解释滑动窗口前，需要看看ACK的应答策略，一般来说，发送端发送一个TCP数据报，那么接收端就应该发送一个ACK数据报。但是事实上却不是这样，发送端将会连续发送数据尽量填满接受方的缓冲区，而接受方对这些数据只要发送一个ACK报文来回应就可以了，这就是ACK的累积特性，这个特性大大减少了发送端和接收端的负担。</description>
    </item>
    
    <item>
      <title>tcp连接的建立与终止</title>
      <link>http://xianyuluo.com/post/tcp%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%BB%BA%E7%AB%8B%E4%B8%8E%E7%BB%88%E6%AD%A2/</link>
      <pubDate>Wed, 29 Nov 2017 19:25:14 +0800</pubDate>
      
      <guid>http://xianyuluo.com/post/tcp%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%BB%BA%E7%AB%8B%E4%B8%8E%E7%BB%88%E6%AD%A2/</guid>
      <description>TCP三次握手 TCP三次握手；简单来说就是通信的双方建立可靠的连接之前必须要做的事情，就是在通信之前要做的事情。而我们常见的双方就是指的 客户端 ---- 服务器。  建立连接过程 首先client端发送连接请求报文，server段接受连接后回复ack报文，并为这次连接分配资源。client端接收到ack报文后也向server段发生ack报文，并分配资源，这样tcp连接就建立了。 建立连接过后干嘛呢？那就是该干嘛干嘛呀，就可以传输数据了。
TCP四次挥手 TCP四次挥手：由于TCP协议的可靠性，所以它再结束通信之前也会有一个流程来确认数据已经传输完成，在网络线路当中没有残留的数据包。  断开连接过程 中断连接端可以是Client端，也可以是Server端。假设Client端发起中断连接请求，也就是发送FIN报文。Server端接到FIN报文后，意思是说&amp;rdquo;我Client端没有数据要发给你了&amp;rdquo;（此时的Client是处于FIN_WAIT状态），但是如果你还有数据没有发送完成，则不必急着关闭Socket，可以继续发送数据。所以你先发送ACK，&amp;rdquo;告诉Client端，你的请求我收到了，但是我还没准备好，请继续你等我的消息&amp;rdquo;。这个时候Client端就进入FIN_WAIT状态，继续等待Server端的FIN报文。当Server端确定数据已发送完成，则向Client端发送FIN报文，&amp;rdquo;告诉Client端，好了，我这边数据发完了，准备好关闭连接了&amp;rdquo;。Client端收到FIN报文后，&amp;rdquo;就知道可以关闭连接了，但是他还是不相信网络，怕Server端不知道要关闭，所以发送ACK后进入TIME_WAIT状态，如果Server端没有收到ACK则可以重传。“，Server端收到ACK后，&amp;rdquo;就知道可以断开连接了&amp;rdquo;。Client端等待了2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，我Client端也可以关闭连接了。Ok，TCP连接就这样关闭了！
什么是MSL MSL是一个时间概念，指的是数据包在链路中的最大生存时间，如果超过这个时间，数据包就会被丢掉。主动发起断开连接的一方会在TIME_WAIT时等待2MSL，因为包要一个来回。所以有时候也称TIME_WAIT状态为2MSL状态。  什么时候哪一方会出现TIME_WAIT TCP四次挥手的时候主动发起FIN报文的一方会处于TIME_WAIT状态。  TIME_WAIT的好和坏 TIME_WAIT这个东西有没有好处呢？那有没有坏处呢？ 答案是都有的。好处就是它保证了在断开连接之前数据传输的完整性；那坏处是什么呢？想象一下，如果是服务器主动发起的FIN报文，那它就会处于TIME_WAIT状态，那肯定就会占用一定系统资源。想象一下，如果并发量超级大的时候，那服务器岂不是会崩溃了。  技术交流可加QQ群：774332965</description>
    </item>
    
    <item>
      <title>使用COW让浏览器正确上网</title>
      <link>http://xianyuluo.com/post/cow/</link>
      <pubDate>Mon, 23 Oct 2017 21:35:00 +0800</pubDate>
      
      <guid>http://xianyuluo.com/post/cow/</guid>
      <description>概述 防火长城（英文名称Great Firewall of China，简写为Great Firewall，缩写GFW），也称中国防火墙或中国国家防火墙，指中华人民共和国政府在其管辖因特网内部建立的多套网络审查系统的总称，包括相关行政审查系统。 当使用浏览器访问google、facebook、youtube这些网站时都被GFW拦于门外，但是有些站点又是可以访问的，比如github.com；这就造成一个问题，我怎么知道那些网站是可以访问，哪些不能访问的站点又该怎么办呢？ COW 介绍 COW 是一个简化穿墙的 HTTP 代理服务器。COW 的设计目标是自动化，理想情况下用户无需关心哪些网站无法访问，可直连网站也不会因为使用二级代理而降低访问速度。 简单来说就是国内能访问的就直接访问，不能访问的就走代理访问。
COW优点  自动检测网站是否被墙，仅对被墙网站使用二级代理 自动生成包含直连网站的PAC文件，访问这些网站时可不使用COW  COW缺点  仅支持浏览器使用  架构图  客户端和一台内网服务器建立连接 内网服务器和一台香港服务器建立连接 当客户端访问国内网站时，就直接走内网服务器代理；当客户端访问国外网站时，就先走内网服务器，然后再通过内网服务器和香港服务器之间的SOCK链接访问。  服务部署步骤 香港服务器(6.</description>
    </item>
    
    <item>
      <title>OSI七层协议详细讲解</title>
      <link>http://xianyuluo.com/post/osi%E4%B8%83%E5%B1%82%E5%8D%8F%E8%AE%AE%E8%AF%A6%E7%BB%86%E8%AE%B2%E8%A7%A3/</link>
      <pubDate>Mon, 05 Dec 2016 10:20:05 +0800</pubDate>
      
      <guid>http://xianyuluo.com/post/osi%E4%B8%83%E5%B1%82%E5%8D%8F%E8%AE%AE%E8%AF%A6%E7%BB%86%E8%AE%B2%E8%A7%A3/</guid>
      <description>今天我们从高到低依次来讲解。 可能有些人不是很详细的了解OSI各层所对应的协议，之前我也不是很了解，所以就把每层对应的协议也一起写在了每层的最后
应用层 主要功能：就是处理网络应用。比如文件传输、电子邮件、文件服务、虚拟终端 详细说明：直接为服务端服务，提供各类应用过程的接口和用户接口。例如HTTP、TELNET、FTP、SMTP、DNS、NFS等 对应TCP/IP协议族协议：TFTP、HTTP、SNMP、FTP、SMTP、DNS、TELNET
表示层 主要功能：数据的表示。比如数据格式化、代码转换、数据加密 详细说明：使应用层可以根据其服务解释数据的含义。通常包括数据的编码的约定、本地语法的转换。例如JPEG、ASCII、GIF、MPEG 对应TCP/IP协议族协议：注意，注意。没有协议
会话层 主要功能：互联主机的通信。解除或建立与别的节点的联系 详细说明：负者管理远程用户或进程间的通信，通常包括通信控制、检查点设置、重建终端的传输链路、名字查找和安全验证服务。例如RPC和SQL等 对应TCP/IP协议族协议：注意，注意。没有协议
传输层 主要功能：端到端连接。提供端到端的接口来发送和接收数据 详细说明：实现发送端和接收端的端到端的数据分组传送，负者保证实现数据包的无差错、无丢失、无冗余和按顺序地传输。其服务的访问点为端口。 对应TCP/IP协议族协议：TCP、UDP
网络层 主要功能：分组传输和路由选择。为数据包选择路由 详细说明：通过网络连接交换传输层实体发出的数据，解决路由选择、网络拥塞的问题。服务访问的点为网络地址（IP地址） 对应TCP/IP协议族协议：IP、ICMP、IGMP、OSPF</description>
    </item>
    
    <item>
      <title>OSI/ISO七层——TCP/IP四层</title>
      <link>http://xianyuluo.com/post/osi-iso%E4%B8%83%E5%B1%82/</link>
      <pubDate>Wed, 30 Nov 2016 16:31:48 +0800</pubDate>
      
      <guid>http://xianyuluo.com/post/osi-iso%E4%B8%83%E5%B1%82/</guid>
      <description>OSI：一个国际组织 ISO：OSI提出的网络的7层架构
TCP：传输控制协议IP：数据报协议 TCP/IP：TCP/IP为很大的一个协议族，里面包含了非常多的协议。如：TCP、IP、UDP、ARP、ICMP、RARP、IGMP&amp;hellip;&amp;hellip;
他们的对应关系如下图所示： 技术交流可加QQ群：774332965

微信订阅号同步：时下IT</description>
    </item>
    
    <item>
      <title>IP协议</title>
      <link>http://xianyuluo.com/post/ip%E5%8D%8F%E8%AE%AE/</link>
      <pubDate>Thu, 24 Nov 2016 23:20:16 +0800</pubDate>
      
      <guid>http://xianyuluo.com/post/ip%E5%8D%8F%E8%AE%AE/</guid>
      <description>前言 TCP/IP协议是一个很大协议族，里面包含了IP协议、TCP协议、UDP协议、ICMP协议、IGMP&amp;hellip;&amp;hellip;等等的协议；而IP、TCP就是其中很重要两个的协议。今天我们就来一起简单的分析一下IP协议。
IP协议简介 IP协议是TCP/IP协议的核心，所有的TCP，UDP，IMCP，IGCP的数据都以IP数据格式传输。要注意的是，IP不是可靠的协议，这是说，IP协议没有提供一种数据未传达以后的处理机制；而它的上层协议TCP就具有这个功能。  什么是上层协议？就是距离用户更近的协议，比如http、ftp、TCP等等，而这些协议都是基于IP协议的，所以说是IP协议的上层协议。  IP协议报格式 今天先不挨个解释，我们先来看一看其中有趣的两项。 *8位生存时间TTL*：TTL是一个控制IP数据报在传输过程中的有效时间的类型，详细的可以参考LaoXianYu的TTL，接下来我们来详细的说它后面的那8位。
*8位协议*：开头说了，IP协议是一个不可靠的协议，它还有可靠的上层协议；那上层协议用的是什么协议呢？究竟是TCP还是UDP，答案就在这 8位协议 上。这儿的8位就指出了IP协议的上层用的什么协议。
Linux系统的朋友可以查看 /etc/protocols 这个文件。 (注意：这个图没有截完，下面还有很多，一直到了142了吧) 该文件是网络协议定义文件，里面记录了TCP/IP协议族的所有协议类型。文件中的每一行对应一个协议类型，它有3个字段，中间用TAB或空格分隔，分别表示“协议名称”、“协议号”和“协议别名”。
也就是说，如果这儿8位协议的值为 1，那上层就是用的ICMP；如果为 2，那上层用的就是IGMP；如果为 6，那上层用的就是TCP。</description>
    </item>
    
    <item>
      <title>ICMP</title>
      <link>http://xianyuluo.com/post/icmp%E5%8D%8F%E8%AE%AE/</link>
      <pubDate>Wed, 23 Nov 2016 22:42:02 +0800</pubDate>
      
      <guid>http://xianyuluo.com/post/icmp%E5%8D%8F%E8%AE%AE/</guid>
      <description>什么是ICMP？ ICMP是（Internet Control Message Protocol）Internet控制报文协议。  ICMP协议有什么用？ 它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。控制消息是指网络通不通、主机是否可达、路由是否可用、端口是否可达等网络本身的消息。  这些控制消息虽然并不传输用户数据，但是对于用户数据的传递起着重要的作用。也就是说每次在传输IP数据包之前，都会利用ICMP去检测一番，然后再决定是否传输IP数据包。  ICMP协议类型 其中有 0：回显应答 8：回显请求 Ping命令就是利用这两种类型的ICMP数据包。 一台主机向一个节点发送一个Type=8的ICMP报文，如果途中没有异常（例如被路由器丢弃、目标不回应ICMP或传输失败），则目标返回Type=0的ICMP报文，说明这台主机存在，更详细的traceroute通过计算ICMP报文通过的节点来确定主机与目标之间的网络距离。 （在上一篇中说道Tracroute利用了TTL，同时traceroute也利用了ICMP）
技术交流可加QQ群：774332965</description>
    </item>
    
    <item>
      <title>TTL</title>
      <link>http://xianyuluo.com/post/ttl/</link>
      <pubDate>Tue, 22 Nov 2016 23:32:39 +0000</pubDate>
      
      <guid>http://xianyuluo.com/post/ttl/</guid>
      <description>什么是TTL？ 就是用来记录IP数据包从发出经过了多少路由！ TTL占8bit，所以它的最大值就是255；每当数据包经过一个路由器时，TTL的值就会减1，当为0时，就把这个数据包给丢弃。较老的系统的TTL初始化值为15或32，现在一般的为255。  为什么需要TTL？ 为了防止IP数据包在选路时无休止的在网络中流动。  Traceroute成功利用了TTL *Traceroute*：路由探测工具，用它可以知道从源地址到目的地址需要经过哪些路由器 *使用方法*：Traceroute 域名 / IP，你使用的时候可能会看到很多的 &amp;lsquo;*&amp;lsquo;，这是正常的，因为国内的网络环境有很多都是隐蔽的。 *原理*：
我们现在可以猜想一下Traceroute程序的操作过程。它发送一份TTL字段为1的IP数据报给目的主机。处理这份数据报的第一个路由器将TTL值减1，丢弃该数据报，并发回一份超时ICMP报文。这样就得到了该路径中的第一个路由器的地址。然后Traceroute程序发送一份TTL值为2的数据报，这样我们就可以得到第二个路由器的地址。继续这个过程直至该数据报到达目的主机。但是目的主机哪怕接收到TTL值为1的IP数据报，也不会丢弃该数据报并产生一份超时ICMP报文，这是因为数据报已经到达其最终目的地。  *那么我们该如何判断是否已经到达目的主机了呢*？
Traceroute程序发送一份UDP数据报给目的主机，但它选择一个不可能的值作为UDP端口号（大于30000），使目的主机的任何一个应用程序都不可能使用该端口。因为，当该数据报到达时，将使目的主机的UDP模块产生一份“端口不可达”错误的ICMP报文。这样，Traceroute程序所要做的就是区分接收到的ICMP报文是超时还是端口不可达，以判断什么时候结束。  看到这儿，是不是觉得Traceroute有点老奸巨猾呢？没错，就是的！</description>
    </item>
    
    <item>
      <title>arp协议</title>
      <link>http://xianyuluo.com/post/arp%E5%8D%8F%E8%AE%AE/</link>
      <pubDate>Mon, 21 Nov 2016 23:48:12 +0800</pubDate>
      
      <guid>http://xianyuluo.com/post/arp%E5%8D%8F%E8%AE%AE/</guid>
      <description>什么是ARP协议？ 协议都是电脑之间先约定好的一些规则而已！  ARP协议是干嘛的？ 将IP地址转换为MAC地址！  为什么需要ARP协议？ 首先，我们的清楚，电脑之间进行的通信是依靠MAC地址来通信的。就说你必须知道对方主机的MAC地址（MAC地址才是唯一的），然后你才能给它发送信息，然后它的网卡收到信息过后才能进行处理。但是我们一般都不记MAC地址，退而求其次，我们记得是IP地址；再退一步我们就是记得 域名 了，比如说 www.google.com。 域名----&amp;gt;IP地址----&amp;gt;MAC地址，域名到IP地址我们是通过DNS来完成的（不明白DNS的可以参考  xianyuLuo的这篇文章。而从IP地址到MAC地址，我们用的就是arp。
ARP协议的工作过程
当主机要发送一个IP包的时候，会首先查一下自己的ARP高速缓存（就是一个IP-MAC地址对应表缓存），如果查询的IP－MAC值对不存在，那么主机就向网络发送一个ARP协议广播包，这个广播包里面就有待查询的IP地址，而直接收到这份广播的包的所有主机都会查询自己的IP地址，如果收到广播包的某一个主机发现自己符合条件，那么就准备好一个包含自己的MAC地址的ARP包传送给发送ARP广播的主机，而广播主机拿到ARP包后会更新自己的ARP缓存（就是存放IP-MAC对应表的地方）。发送广播的主机就会用新的ARP缓存数据准备好数据链路层的的数据包发送工作。
arp缓存表例子
windows下执行&amp;rdquo;arp -a&amp;rdquo;命令： linux下执行&amp;rdquo;arp -a&amp;rdquo;命令： 技术交流可加QQ群：774332965</description>
    </item>
    
    <item>
      <title>DNS解析</title>
      <link>http://xianyuluo.com/post/dns%E8%A7%A3%E6%9E%90/</link>
      <pubDate>Sun, 20 Nov 2016 23:16:07 +0800</pubDate>
      
      <guid>http://xianyuluo.com/post/dns%E8%A7%A3%E6%9E%90/</guid>
      <description>什么是DNS解析？ 就是把域名转换为IP地址的一个过程  为什么需要DNS解析？ 以前都是靠 /etc/hosts 文件来解析域名的，每解析一个域名就需要在文件里面添加一条对应记录。后来由于互联网的迅速发展，域名已经数不胜数了。如果这个时候还是一条一条记录的写在/etc/hosts 文件里面的话，那这个文件估计就超级大了。于是就有了DNS解析，由DNS服务器来解析域名。  DNS域名解析过程有两种方法：递归解析、迭代解析
递归解析： 递归解析就相当于你把这件事情交给第三个人去做，不管他怎么做，反正最后把域名对应的IP地址交给你就是了。而这第三个人就是DNS服务器，这也是我们生活中用的比较多的一种方法。一般用的就是电信的 114.114.114.114  迭代解析： 迭代解析就是你自己去找。 全球的根域名服务器一共有13台，你自己去一级一级的找下去，最终找到自己想解析的域名。  例子： 解析 www.</description>
    </item>
    
    <item>
      <title>cache和buffer的区别</title>
      <link>http://xianyuluo.com/post/cache-buffer/</link>
      <pubDate>Sat, 19 Nov 2016 23:46:50 +0800</pubDate>
      
      <guid>http://xianyuluo.com/post/cache-buffer/</guid>
      <description>Cache：高速缓存 Buffer：高速缓冲
相同之处：都是用于解决不同主件速度不匹配的问题。 Cache：是用于解决CPU和内存的速度不匹配的。因为CPU每次都是从内存当中提取数据，而且CPU的速度远远高于内存的速度，CPU从内存读取数据时就会等待很长的时间；Cache就保存着CPU刚刚使用过的数据或者经常用到的数据，这时CPU从Cache中提取数据就会快很多，这样减少了CPU的等待时间，提升了系统性能。  所以说Cache是位于 CPU和内存 之间的容量较小但速度很快的存储器。
Buffer：主要是用于解决速度不同的设备之间的传输问题。一般会用在磁盘之间；比如一个USB2.0的磁盘要拷贝文件到一个USB3.0的磁盘，很明显3.0的速度要远比2.0的快得多，如果3.0的一直去读取2.0的数据的话，那这样就会浪费它的速度优势；所以可以先把存储速度慢的数据先放到Buffer里面，当达到一定程度时，存储速度快的就从Buffer里面将数据取出来；这样便可以大大的提高利用率。  所以说Buffer是位于存储速度不同步的设备之间的一个缓冲区。
技术交流可加QQ群：774332965

微信订阅号同步：时下IT</description>
    </item>
    
  </channel>
</rss>