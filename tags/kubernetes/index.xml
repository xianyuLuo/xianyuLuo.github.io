<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kubernetes on xianyuLuo Blog</title>
    <link>http://xianyuluo.com/tags/kubernetes/</link>
    <description>Recent content in Kubernetes on xianyuLuo Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>cn-ZH</language>
    <lastBuildDate>Tue, 12 Mar 2019 22:11:13 +0800</lastBuildDate>
    
	<atom:link href="http://xianyuluo.com/tags/kubernetes/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Prometheus监控k8s(一)——监控框架调研</title>
      <link>http://xianyuluo.com/post/prometheus%E7%9B%91%E6%8E%A7k8s%E4%B8%80%E7%9B%91%E6%8E%A7%E6%A1%86%E6%9E%B6%E8%B0%83%E7%A0%94/</link>
      <pubDate>Tue, 12 Mar 2019 22:11:13 +0800</pubDate>
      
      <guid>http://xianyuluo.com/post/prometheus%E7%9B%91%E6%8E%A7k8s%E4%B8%80%E7%9B%91%E6%8E%A7%E6%A1%86%E6%9E%B6%E8%B0%83%E7%A0%94/</guid>
      <description>背景 由于容器化和微服务的大力发展，Kubernetes基本已经统一了容器管理方案，当我们使用Kubernetes来进行容器化管理的时候，全面监控Kubernetes也就成了我们第一个需要探索的问题。我们需要监控kubernetes的ingress、service、deployment、pod&amp;hellip;&amp;hellip;等等服务，已达到随时掌握Kubernetes集群的内部状况。
此文章是Prometheus监控系列的第一篇，目的也很明确，旨在于寻找一套能够胜任kubernetes集群监控的架构。
k8s监控方案调研 1、cAdvisor + InfluxDB + Grafana 2、Heapster + InfluxDB + Grafana [x] 3、Promethus + kube-state-metrics + Grafana
 Grafana: 开源DashBoard，后端支持多种数据库，如：Influxdb、Prometheus&amp;hellip;，插件也比较多，功能强大。非常适合用于做展示。
 InfluxDB: 开源时间序列数据库，性能高效
 cAdvisor: 来自 Google 的容器监控工具，也是 Kubelet 内置的容器资源收集工具。它会自动收集本机容器 CPU、内存、网络和文件系统的资源占用情况，并对外提供 cAdvisor 原生的 API。随 kubelet 启动 &amp;ndash;cadvisor-port = 1
   Heapster: 由于 cAdvisor 只提供了单机的容器资源占用情况，而 Heapster 则提供了整个集群的资源监控（kubernetes 1.11 之前，hpa都是从heapster获取数据），并支持持久化数据存储到 InfluxDB   Promethues: 提供强大的数据采集、数据存储、数据展示、告警等，天生完美支持kubernetes，CNCF基金会的第二个成员，第一个是Kubernetes。而且Prometheus里面很多思想都来源于Google内部的监控系统Borgmon，可以说是Google的干儿子。   kube-state-metrics在这里作为prometheus的一个exporter来使用，提供deployment、daemonset、cronjob等服务的监控数据，由kubernestes官方提供，与prometheus紧密结合。 更多关于kube-state-metrics的信息：https://github.com/kubernetes/kube-state-metrics  Prometheus优势 Prometheus和kubernetes相亲相爱 Google干儿子，大厂维护，而且最重要的一点是完美支持Kubernetes
规范定义 Prometheus对于应用层的监控，定义了一个良好的规范，只需要应用提供接口获取日志就可以了
Prometheus可以在各个层面实现监控，如下  基础设施层：监控各个主机服务器资源(包括Kubernetes的Node和非Kubernetes的Node)，如CPU,内存,网络吞吐和带宽占用,磁盘I/O和磁盘使用等指标。 中间件层：监控独立部署于Kubernetes集群之外的中间件，例如：MySQL、Redis、RabbitMQ、ElasticSearch、Nginx等。 Kubernetes集群：监控Kubernetes集群本身的关键指标 Kubernetes集群上部署的应用：监控部署在Kubernetes集群上的应用  基于以上三点，所以最终选择使用Prometheus来监控Kubernetes集群。
Kubernetes集群监控架构 在具体讨论Prometheus监控架构之前，再来看几个实际的问题
 如果有多个Kubernetes集群，怎么做？
 多个Kubernetes集群的监控数据怎么处理？
 告警应该怎么集中并去重？
  好在这些问题对Prometheus来说都不是难事，最终，我们采取 Prometheus + kube-state-metrics + Alertmanager + Grafana 架构来做Kubernetes集群监控。监控系统具体架构如下
使用这个架构，那上面所提到的三个问题将不再是问题。
详解 K8s集群： k8s集群-1/-2/-3为需要被监控的集群，就是业务集群。每个集群内部都部署了一个Prometheus，主要由两部分组成 prometheus-server + kube-state-metrics。
prometheus-server：使用一个带RBAC权限的账号采集集群中现有监控信息（其实是从cadvisor获取）和节点信息。
kube-state-metrics：这里作为prometheus的exporter使用。因为prometheus不能获取集群中Deployment, Job, CronJob的监控信息。 部署kube-state-metrics的时候，svc一定要带一个annotations：prometheus.io/scrape: &amp;lsquo;true&amp;rsquo;（==这非常重要==）
监控汇总 监控汇总其实就是一个Prometheus-server，用于将各个散落在各地的监控数据汇总起来，统一管理。
核心思想是利用Prometheus的federation机制，从其他集群pull数据。这样其他集群的prometheus只需要短暂存储数据，汇总之后再做长期存储；同时还可以统一做告警判断和数据展示。
Prometheus官方Federation示例
- job_name: &#39;federate&#39; scrape_interval: 15s honor_labels: true metrics_path: &#39;/federate&#39; params: &#39;match[]&#39;: - &#39;{job=&amp;quot;prometheus&amp;quot;}&#39; - &#39;{__name__=~&amp;quot;prometheus_job:.*&amp;quot;}&#39; static_configs: - targets: - &#39;source-prometheus-1:9090&#39; - &#39;source-prometheus-2:9090&#39; - &#39;source-prometheus-3:9090&#39;  这段配置所属的Prometheus将从source-prometheus-1 ~ 3这3个Prometheus的/federate端点拉取监控数据。 match[]参数指定了只拉取带有job=”prometheus标签的指标，或者名称以prometheus_job开头的指标。</description>
    </item>
    
    <item>
      <title>Ingress介绍</title>
      <link>http://xianyuluo.com/post/ingress%E4%BB%8B%E7%BB%8D/</link>
      <pubDate>Fri, 09 Nov 2018 18:29:30 +0800</pubDate>
      
      <guid>http://xianyuluo.com/post/ingress%E4%BB%8B%E7%BB%8D/</guid>
      <description>&lt;h1 id=&#34;概念&#34;&gt;概念&lt;/h1&gt;

&lt;p&gt;Ingress是kubernetes1.1之后官方提出的一个标准，按照这套标准它有多种实现，比如 nginx-ingress-controller、traefik-ingress-controller、kong-ingress-controller，这3中都是官方推荐的。Ingress的出现解决了Service的短板：只能在tcp层面做负载均衡。而ingress可以方便的做http/https层面的负载均衡。一个是在4层，一个在7层。ingress就是控制客户端从入口连接到k8s集群服务的规则的集合！&lt;/p&gt;

&lt;h3 id=&#34;ingress出现之前-服务暴露是这样的&#34;&gt;ingress出现之前，服务暴露是这样的：&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://dl-blog.laoxianyu.cn/image2018-8-10_14-6-49.png&#34; alt=&#34;image&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;ingress出现之后-服务暴露是这样的&#34;&gt;ingress出现之后，服务暴露是这样的：&lt;/h3&gt;</description>
    </item>
    
    <item>
      <title>traefik在kubernetes中的应用</title>
      <link>http://xianyuluo.com/post/traefik%E5%9C%A8kubernetes%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/</link>
      <pubDate>Mon, 10 Sep 2018 22:08:46 +0800</pubDate>
      
      <guid>http://xianyuluo.com/post/traefik%E5%9C%A8kubernetes%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/</guid>
      <description>目的： 通过本篇文章，能够简单了解和掌握Traefik在Kubernetes中的应用
如果不了解ingress和ingress-controller概念，请先看前一篇文章。http://km.oa.dragonest.com/x/RoFf
traefik介绍： 开源的微服务网关服务，支持Mesos、Docker、Rancher、Kubernetes等等，也支持直接部署在物理服务器。能够实现负载均衡、HTTPS、自动更新Ingerss配置等等
traefik部署： traefik-deployment部署 apiVersion: extensions/v1beta1 kind: Deployment metadata: name: traefik-ingress-controller namespace: traefik labels: k8s-app: traefik-ingress-lb spec: replicas: 1 selector: matchLabels: k8s-app: traefik-ingress-lb template: metadata: labels: k8s-app: traefik-ingress-lb name: traefik-ingress-lb spec: nodeSelector: traefik-controller-qa: &amp;quot;yes&amp;quot; serviceAccountName: traefik-ingress-controller terminationGracePeriodSeconds: 60 volumes: - name: ssl secret: secretName: traefik-cert - name: config configMap: name: traefik-conf containers: - image: traefik name: traefik-ingress-lb volumeMounts: - mountPath: &amp;quot;/ssl&amp;quot; name: &amp;quot;ssl&amp;quot; - mountPath: &amp;quot;/config&amp;quot; name: &amp;quot;config&amp;quot; ports: - name: http containerPort: 80 - name: admin containerPort: 8080 - name: https containerPort: 443 args: - --configFile=/config/traefik.toml - --web - --kubernetes - --logLevel=INFO  traefik-svc部署 apiVersion: v1 kind: Service metadata: name: traefik-ingress-service namespace: traefik spec: selector: k8s-app: traefik-ingress-lb ports: - protocol: TCP port: 80 name: web - protocol: TCP port: 8080 name: admin - protocol: TCP port: 443 name: https type: LoadBalancer  其他证书、secret、configmap、rbac编排请见文章末尾链接！
实例应用： 该案例中使用website的一个demo站点做为测试，站点内容见： http://website-dev-demo.</description>
    </item>
    
  </channel>
</rss>